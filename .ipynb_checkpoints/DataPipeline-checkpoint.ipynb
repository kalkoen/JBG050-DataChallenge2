{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a508f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c9bf82",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e757c",
   "metadata": {},
   "source": [
    "This notebook is the so-called data pipeline. In this notebook the following is performed\n",
    "- The original streets dataset from https://data.police.uk/ is imported\n",
    "- An LAD-LSOA conversion table is imported\n",
    "- The dataset is scoped and cleaned\n",
    "- The streets dataset is aggregated per LAD instead of per Police Department\n",
    "\n",
    "The goal of this notebook is to have one easily-runnable file that does all dropping, cleaning and aggregating of the data. By directly using the output of this notebook, and this notebook only, consistency of the dataset in later steps is guaranteed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72a662",
   "metadata": {},
   "source": [
    "# Data locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57fed9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = \"data/Jan_2010_Oct_2021\"\n",
    "conversion_table = \"data/conversiontable.csv\"\n",
    "LAD_directory = \"data/LADs\"\n",
    "final_directory = \"data/Output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba3f2c2",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229dc156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_folder, df_cols='all', year='all'):\n",
    "    df_list = []\n",
    "    df = ''\n",
    "\n",
    "    for folder in os.listdir(data_folder):\n",
    "        if year == 'all' or folder.startswith(str(year)):\n",
    "            folder = data_folder + '\\\\' + folder\n",
    "            for data in os.listdir(folder):\n",
    "                file_path = folder + '\\\\' + data\n",
    "\n",
    "                if 'street' in data:\n",
    "                    df_list.append(file_path)\n",
    "\n",
    "    if df_cols == 'all':\n",
    "        df = pd.concat([pd.read_csv(f) for f in tqdm(\n",
    "            df_list, position=0, leave=True)], ignore_index=True)\n",
    "    else:\n",
    "        df = pd.concat([pd.read_csv(f, usecols=df_cols) for f in tqdm(\n",
    "            df_list, position=0, leave=True)], ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874fff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_lsoas_missing(observed_lsoas, lsoa_list):\n",
    "    missing_lsoa = []\n",
    "    for observed_lsoa in observed_lsoas:\n",
    "        if observed_lsoa not in lsoa_list:\n",
    "            missing_lsoa.append(observed_lsoa)\n",
    "    return len(missing_lsoa) != 0\n",
    "# I've never seen an LSOA missing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5953613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_folder(directory):\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "\n",
    "def create_folders(parent_dir, folders):\n",
    "    remove_folder(parent_dir)\n",
    "    os.makedirs(parent_dir)\n",
    "    for folder in folders:\n",
    "        directory = f'{folder}'\n",
    "        path = os.path.join(parent_dir, directory) \n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c231d6",
   "metadata": {},
   "source": [
    "# Loading LAD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4614fdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20193736\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2640516 entries, 0 to 2640515\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   pcd7      object \n",
      " 1   pcd8      object \n",
      " 2   pcds      object \n",
      " 3   dointr    int64  \n",
      " 4   doterm    float64\n",
      " 5   usertype  int64  \n",
      " 6   oa11cd    object \n",
      " 7   lsoa11cd  object \n",
      " 8   msoa11cd  object \n",
      " 9   ladcd     object \n",
      " 10  lsoa11nm  object \n",
      " 11  msoa11nm  object \n",
      " 12  ladnm     object \n",
      " 13  ladnmw    object \n",
      "dtypes: float64(1), int64(2), object(11)\n",
      "memory usage: 282.0+ MB\n"
     ]
    }
   ],
   "source": [
    "dfc = pd.read_csv(conversion_table, encoding=\"latin-1\")\n",
    "dfc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "759ec755",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42622, 385, 385)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsoac = \"lsoa11cd\"\n",
    "ladc = \"ladcd\"\n",
    "ladnm = \"ladnm\"\n",
    "lsoa_list = list(dfc[lsoac].unique())\n",
    "ladc_list = list(dfc[ladc].unique())\n",
    "ladnm_list = list(dfc[ladnm].unique())\n",
    "len(lsoa_list), len(ladc_list), len(ladnm_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12f9f9",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "We define the regions to be loaded and one data cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52cfbcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_streets_df(street):\n",
    "    \n",
    "    na_street = street.dropna(axis=0, how=\"any\")\n",
    "    n_dropped = len(street) - len(na_street)\n",
    "    print(f\"{n_dropped} dropped\")\n",
    "    na_street['Month dt'] = pd.to_datetime(na_street['Month']).dt.to_period('m')\n",
    "    na_street = na_street[ na_street['Month dt'] > '2013-05' ]\n",
    "    \n",
    "    # reasons for dropping:\n",
    "    # avon-and-somerset is not consistent with location data\n",
    "    # btp and west-midlands have missing data\n",
    "    # northern-ireland doesn't use LSOA's, so aggregating by location requires a different approach\n",
    "    drop_regions = [\"Avon and Somerset Constabulary\", \"British Transport Police\", \"West Midlands Police\", \"Police Service of Northern Ireland\"]\n",
    "\n",
    "    #for testing, let's leave all regions for now\n",
    "    drop_regions = []\n",
    "    \n",
    "    na_street = na_street[~(na_street[\"Reported by\"].isin(drop_regions) | na_street[\"Falls within\"].isin(drop_regions))]\n",
    "    \n",
    "    return na_street\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203a69d",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25454639",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_codes = dict(zip(dfc[lsoac], dfc[ladc]))\n",
    "convert_names = dict(zip(dfc[lsoac], dfc[ladnm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39000a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 540/540 [00:13<00:00, 41.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221232 dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20193736\\AppData\\Local\\Temp/ipykernel_1044/2325533159.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  na_street['Month dt'] = pd.to_datetime(na_street['Month']).dt.to_period('m')\n",
      " 35%|███▌      | 190/540 [00:05<00:09, 38.40it/s]"
     ]
    }
   ],
   "source": [
    "street_cols = ['Month', 'Reported by', 'Falls within', 'Location', 'LSOA code', 'LSOA name', 'Crime type']\n",
    "\n",
    "year_range = range(2013, 2022)\n",
    "\n",
    "create_folders(LAD_directory, ladnm_list)\n",
    "\n",
    "for year in year_range:\n",
    "    df_temp = read_data(original_dataset, df_cols=street_cols, year=year)\n",
    "    df_temp = clean_streets_df(df_temp)\n",
    "    df_temp['LAD code'] = df_temp['LSOA code'].map(convert_codes)\n",
    "    df_temp['LAD name'] = df_temp['LSOA code'].map(convert_names)  # add a column with the LAD code\n",
    "    df_temp = df_temp.groupby('LAD name')\n",
    "    df_temp.apply(lambda x: x.to_csv(r'{}/{}/{}.csv'.format(LAD_directory,x.name,year)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a6b2ae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:00<00:00, 16821.43it/s]\n"
     ]
    }
   ],
   "source": [
    "remove_folder(final_directory)\n",
    "os.makedirs(final_directory)\n",
    "for lad in tqdm(ladnm_list):\n",
    "    directory = f'{lad}'\n",
    "    mypath = os.path.join(LAD_directory, directory)\n",
    "    files = [f for f in os.listdir(mypath)]\n",
    "    dfs = [pd.read_csv(os.path.join(mypath, f)).assign(challenge=f) for f in files]\n",
    "    if dfs:\n",
    "        df = pd.concat(dfs, ignore_index=True)\n",
    "        df.to_csv(f'{final_directory}/{lad}.csv')\n",
    "# remove_folder(LAD_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee031e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_folder(LAD_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
